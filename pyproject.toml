[project]
name = "adaptive-rag"
version = "0.1.0"
description = "Adaptive Retrieval-Augmented Generation"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "torch==2.7.0",
    "accelerate==1.7.0",
    "aiohappyeyeballs==2.6.1",
    "aiohttp==3.11.18",
    "aiosignal==1.3.2",
    "aiosqlite==0.21.0",
    "annotated-types==0.7.0",
    "anyio==4.9.0",
    "attrs==25.3.0",
    "banks==2.1.2",
    "beautifulsoup4==4.13.4",
    "bm25s==0.2.12",
    "cbor==1.0.0",
    "certifi==2025.4.26",
    "charset-normalizer==3.4.2",
    "click==8.2.0",
    "colorama==0.4.6",
    "dataclasses-json==0.6.7",
    "datasets==3.6.0",
    "deprecated==1.2.18",
    "dill==0.3.8",
    "dirtyjson==1.0.8",
    "distro==1.9.0",
    "filelock==3.13.1",
    "filetype==1.2.0",
    "flagembedding==1.3.4",
    "frozenlist==1.6.0",
    "fsspec==2024.6.1",
    "greenlet==3.2.2",
    "griffe==1.7.3",
    "h11==0.16.0",
    "hf-xet==1.1.1",
    "httpcore==1.0.9",
    "httpx==0.28.1",
    "huggingface-hub==0.31.2",
    "idna==3.10",
    "ijson==3.4.0",
    "inscriptis==2.6.0",
    "ir-datasets==0.5.10",
    "jinja2==3.1.4",
    "jiter==0.9.0",
    "joblib==1.5.0",
    "llama-cloud==0.1.21",
    "llama-cloud-services==0.6.15",
    "llama-index==0.12.36",
    "llama-index-agent-openai==0.4.7",
    "llama-index-cli==0.4.1",
    "llama-index-core==0.12.36",
    "llama-index-embeddings-huggingface==0.5.4",
    "llama-index-embeddings-openai==0.3.1",
    "llama-index-indices-managed-llama-cloud==0.6.11",
    "llama-index-llms-openai==0.3.38",
    "llama-index-multi-modal-llms-openai==0.4.3",
    "llama-index-program-openai==0.3.1",
    "llama-index-question-gen-openai==0.3.0",
    "llama-index-readers-file==0.4.7",
    "llama-index-readers-llama-parse==0.4.0",
    "llama-index-retrievers-bm25==0.5.2",
    "llama-parse==0.6.12",
    "lxml==5.4.0",
    "lz4==4.4.4",
    "markupsafe==2.1.5",
    "marshmallow==3.26.1",
    "mpmath==1.3.0",
    "multidict==6.4.3",
    "multiprocess==0.70.16",
    "mypy-extensions==1.1.0",
    "nest-asyncio==1.6.0",
    "networkx==3.3",
    "nltk==3.9.1",
    "numpy==2.2.5",
    "openai==1.78.1",
    "packaging==25.0",
    "pandas==2.2.3",
    "peft==0.15.2",
    "pillow==11.2.1",
    "platformdirs==4.3.8",
    "propcache==0.3.1",
    "protobuf==6.31.0",
    "psutil==7.0.0",
    "pyarrow==20.0.0",
    "pydantic==2.11.4",
    "pydantic-core==2.33.2",
    "pypdf==5.5.0",
    "pystemmer==2.2.0.3",
    "python-dateutil==2.9.0.post0",
    "python-dotenv==1.1.0",
    "pytz==2025.2",
    "pyyaml==6.0.2",
    "regex==2024.11.6",
    "requests==2.32.3",
    "safetensors==0.5.3",
    "scikit-learn==1.6.1",
    "scipy==1.15.3",
    "sentence-transformers==4.1.0",
    "sentencepiece==0.2.0",
    "setuptools==70.2.0",
    "six==1.17.0",
    "sniffio==1.3.1",
    "soupsieve==2.7",
    "sqlalchemy==2.0.41",
    "striprtf==0.0.26",
    "sympy>=1.13.3",
    "tenacity==9.1.2",
    "threadpoolctl==3.6.0",
    "tiktoken==0.9.0",
    "tokenizers==0.21.1",
    "tqdm==4.67.1",
    "transformers==4.51.3",
    "trec-car-tools==2.6",
    "triton==3.3.0",
    "typing-extensions==4.12.2",
    "typing-inspect==0.9.0",
    "typing-inspection==0.4.0",
    "tzdata==2025.2",
    "unlzw3==0.2.3",
    "urllib3==2.4.0",
    "warc3-wet==0.2.5",
    "warc3-wet-clueweb09==0.2.5",
    "wrapt==1.17.2",
    "xxhash==3.5.0",
    "yarl==1.20.0",
    "zlib-state==0.1.9",
]

[[tool.uv.index]]
name = "pytorch-cu118"
url = "https://download.pytorch.org/whl/cu118"
explicit = true

[tool.uv.sources]
torch = [
  { index = "pytorch-cu118", marker = "sys_platform == 'linux' or sys_platform == 'win32'" },
]
